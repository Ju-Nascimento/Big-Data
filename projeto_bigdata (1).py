# -*- coding: utf-8 -*-
"""Projeto_BigData.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xvFdOL4n4kBmCn3VaJ8PAaZfIdke4Kq2

**Este código configura o ambiente para rodar o Apache Spark no Google Colab, instalando o Java necessário, baixando e extraindo o Spark, 
e configurando variáveis de ambiente. Também instala as bibliotecas findspark e pyspark, essenciais para inicializar e utilizar o Spark no Python,
 preparando para o processamento de dados com PySpark.**
"""

!apt-get install openjdk-8-jdk-headless -qq> /dev/null
!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz
!tar xf spark-3.1.2-bin-hadoop2.7.tgz
!wget "https://raw.githubusercontent.com/Ju-Nascimento/Big_Data/refs/heads/main/Dados.csv"
!mkdir CSV
import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] ="/content/spark-3.1.2-bin-hadoop2.7"
!pip install -q findspark
!pip install pyspark
import findspark
findspark.init()

"""**Inicializando uma sessão do Spark para processamento local e lendo o arquivo Dados.csv em um DataFrame do PySpark, 
inferindo automaticamente os tipos de dados e considerando a primeira linha como cabeçalho.
 Ele, então, exibe o conteúdo do DataFrame carregado.**"""

from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("MyApp") \
    .master("local[*]") \
    .getOrCreate()

file_path = "/content/Dados.csv"

# Ler o arquivo CSV
df = spark.read.csv(file_path, header=True, inferSchema=True, encoding='ISO-8859-1')
df.show()

"""**Convertendo e limpando colunas para os tipos corretos e removendo caracteres indesejados. 
E tambem selecionando apenas as colunas que iremos utilizar. 
Em seguida, ele exibe o esquema final do DataFrame para confirmar as alterações feitas.**"""

from pyspark.sql.functions import col, regexp_replace, to_date

def clean_and_convert(df, column_name, target_type):
    if target_type == "int":
        df = df.withColumn(column_name, regexp_replace(column_name, "[^0-9]", ""))
        df = df.withColumn(column_name, col(column_name).cast("int"))
    elif target_type == "double":
        df = df.withColumn(column_name, regexp_replace(column_name, "[^0-9.]", ""))
        df = df.withColumn(column_name, col(column_name).cast("double"))
    return df

df = spark.read.csv(file_path, header=True, inferSchema=True)

df = df.withColumn("Release Date", to_date(col("Release Date"), "dd/MM/yyyy"))

columns_to_convert = {
    "Spotify Streams": "int", "Spotify Playlist Count": "int",
    "Spotify Playlist Reach": "int", "Spotify Popularity": "double",
    "YouTube Views": "int", "YouTube Likes": "int", "TikTok Posts": "int",
    "TikTok Likes": "int", "TikTok Views": "int", "YouTube Playlist Reach": "int",
    "Apple Music Playlist Count": "double", "AirPlay Spins": "int",
    "SiriusXM Spins": "double", "Deezer Playlist Count": "double",
    "Deezer Playlist Reach": "int", "Amazon Playlist Count": "double",
    "Pandora Streams": "int", "Pandora Track Stations": "int",
    "Soundcloud Streams": "int", "Shazam Counts": "int",
    "Explicit Track": "int"
}

for column, target_type in columns_to_convert.items():
    df = clean_and_convert(df, column, target_type)

dataframe = df.select(
    'Track', 'Album Name', 'Artist', 'Release Date',
    'Spotify Streams', 'Spotify Popularity',
    'Spotify Playlist Count', 'YouTube Views',
    'YouTube Likes', 'TikTok Posts', 'TikTok Likes',
    'TikTok Views', 'YouTube Playlist Reach',
    'Explicit Track'
)

dataframe = dataframe.filter(col("Artist") != "MUSIC LAB JPN")

dataframe.printSchema()

"""**Agrupa o DataFrame por artista, calcula a soma total dos streams em plataformas como Spotify, TikTok e YouTube,
 e seleciona os 10 artistas com o maior total de streams. Em seguida, exibe os resultados e salva o DataFrame como um arquivo CSV.**"""

from pyspark.sql import functions as F

combined_data = dataframe.groupBy("Artist") \
    .agg(
        F.sum("Spotify Streams").alias("Total Spotify Streams"),
        F.sum("TikTok Views").alias("Total TikTok Views"),
        F.sum("YouTube Views").alias("Total YouTube Views")
    ) \
    .orderBy(F.desc("Total Spotify Streams")).limit(10)

print("Artistas com total de streams por plataforma:")
combined_data.show(10)

combined_data.toPandas().to_csv("/content/CSV/top_artistas.csv", index=False)

"""**Agrupa o DataFrame por nome do álbum e artista, calcula a soma total dos streams no Spotify,
 e seleciona os 10 álbuns com o maior total de streams. Em seguida, exibe os resultados e salva o DataFrame como um arquivo CSV**"""

from pyspark.sql.functions import col

albuns_mais_ouvidos = dataframe.groupBy("Album Name", "Artist") \
                        .sum("Spotify Streams") \
                        .withColumnRenamed("sum(Spotify Streams)", "Total Streams") \
                        .orderBy(col("Total Streams").desc()) \
                        .limit(10)

print("Top 10 Albuns mais ouvidos do Spotify")
albuns_mais_ouvidos.show(truncate=False)

albuns_mais_ouvidos.toPandas().to_csv("/content/CSV/top_albuns.csv", index=False)

"""**Agrupa o DataFrame por artista, conta o número de músicas de cada artista e calcula a média de popularidade no Spotify,
 arredondando para uma casa decimal. 
Filtra para incluir apenas artistas com 7 ou mais músicas e seleciona os 10 artistas com a maior média de popularidade.**"""

from pyspark.sql.functions import col, count, avg, round

media = dataframe.groupBy("Artist") \
          .agg(
          count("Track").alias("N° de Musicas"),
          round(avg(col("Spotify Popularity")), 1).alias("Media de Popularidade")
                               ) \
          .filter(col("N° de Musicas") >= 7) \
          .orderBy(col("Media de Popularidade").desc()) \
          .limit(10)

media.show(truncate=False)

media.toPandas().to_csv("/content/CSV/media.csv", index=False)

"""**Filtra músicas lançadas de 2020 a 2024 no DataFrame, agrupando por faixa e artista para calcular a soma total dos streams no Spotify.
 Para cada ano, obtém as cinco músicas mais ouvidas e exibe os resultados, salvando-os como arquivos CSV correspondentes.
   As etapas incluem configurar a política de parsing de tempo, filtrar dados por ano e agrupar os resultados por faixa e artista.**"""

from pyspark.sql import functions as F

spark.conf.set("spark.sql.legacy.timeParserPolicy", "LEGACY")

musicas_pos_2024 = dataframe.filter(F.col("Release Date") > F.lit("2024-01-01"))

musicas_mais_ouvidas = musicas_pos_2024.groupBy("Track", "Artist") \
    .agg(F.sum("Spotify Streams").alias("Total Spotify Streams")) \
    .orderBy(F.desc("Total Spotify Streams")) \
    .limit(5)

print("Musicas lançadas em 2024 mais ouvidas:")
musicas_mais_ouvidas.show(truncate=False)
musicas_mais_ouvidas.toPandas().to_csv("/content/CSV/2024.csv", index=False)

musicas_2023 = dataframe.filter(
    (F.col("Release Date") >= F.lit("2023-01-01")) & (F.col("Release Date") <= F.lit("2023-12-31"))
)

musicas_mais_ouvidas_2023 = musicas_2023.groupBy("Track", "Artist") \
    .agg(F.sum("Spotify Streams").alias("Total Spotify Streams")) \
    .orderBy(F.desc("Total Spotify Streams")) \
    .limit(5)

print("Musicas lançadas em 2023 mais ouvidas:")
musicas_mais_ouvidas_2023.show(truncate=False)
musicas_mais_ouvidas_2023.toPandas().to_csv("/content/CSV/2023.csv", index=False)

musicas_2022 = dataframe.filter(
    (F.col("Release Date") >= F.lit("2022-01-01")) & (F.col("Release Date") <= F.lit("2022-12-31"))
)

musicas_mais_ouvidas_2022 = musicas_2022.groupBy("Track", "Artist") \
    .agg(F.sum("Spotify Streams").alias("Total Spotify Streams")) \
    .orderBy(F.desc("Total Spotify Streams")) \
    .limit(5)

print("Musicas lançadas em 2022 mais ouvidas:")
musicas_mais_ouvidas_2022.show(truncate=False)
musicas_mais_ouvidas_2022.toPandas().to_csv("/content/CSV/2022.csv", index=False)


musicas_2021 = dataframe.filter(
    (F.col("Release Date") >= F.lit("2021-01-01")) & (F.col("Release Date") <= F.lit("2021-12-31"))
)

musicas_mais_ouvidas_2021 = musicas_2021.groupBy("Track", "Artist") \
    .agg(F.sum("Spotify Streams").alias("Total Spotify Streams")) \
    .orderBy(F.desc("Total Spotify Streams")) \
    .limit(5)


print("Musicas lançadas em 2021 mais ouvidas:")
musicas_mais_ouvidas_2021.show(truncate=False)
musicas_mais_ouvidas_2021.toPandas().to_csv("/content/CSV/2021.csv", index=False)


musicas_2020 = dataframe.filter(
    (F.col("Release Date") >= F.lit("2020-01-01")) & (F.col("Release Date") <= F.lit("2020-12-31"))
)

musicas_mais_ouvidas_2020 = musicas_2020.groupBy("Track", "Artist") \
    .agg(F.sum("Spotify Streams").alias("Total Spotify Streams")) \
    .orderBy(F.desc("Total Spotify Streams")) \
    .limit(5)

print("Musicas lançadas em 2020 mais ouvidas:")
musicas_mais_ouvidas_2020.show(truncate=False)
musicas_mais_ouvidas_2020.toPandas().to_csv("/content/CSV/2020.csv", index=False)

"""**Compara o total de streams e visualizações de três artistas (Bad Bunny, Taylor Swift e The Weeknd)
 nas plataformas Spotify, YouTube e TikTok. E cria um grafico para exebir os resultados**"""

from pyspark.sql import functions as F
import matplotlib.pyplot as plt

artistas = ["Bad Bunny", "Taylor Swift", "The Weeknd"]
cores = ['#4169E1', '#FF69B4', '#FF0000']
platforms = ['Spotify Streams', 'YouTube Views', 'TikTok Views']

def obter_totais(artista):
    dados = dataframe.filter(F.col("Artist") == artista).agg(
        *[F.sum(plataforma).alias(f"Total {plataforma}") for plataforma in platforms]
    ).collect()[0]
    return [dados[f"Total {plataforma}"] or 0 for plataforma in platforms]

totais = [obter_totais(artista) for artista in artistas]

plt.figure(figsize=(12, 6))
x = range(len(platforms))
width = 0.25

for i, (total, cor) in enumerate(zip(totais, cores)):
    plt.bar([p + width * (i - 1) for p in x], total, width=width, color=cor, label=artistas[i])

plt.ylabel('Número de Views/Streams')
plt.title(f'Comparação de Views: {", ".join(artistas)}')
plt.xticks(x, platforms)
plt.legend()
plt.tight_layout()
plt.show()

"""**Gera um gráfico de pizza que ilustra a distribuição das visualizações de Taylor Swift nas plataformas Spotify, YouTube e TikTok. 
O código filtra os dados do DataFrame para obter as visualizações do artista, 
tratando valores nulos como zero, e plota um gráfico de pizza com porcentagens e cores específicas para cada plataforma,
 destacando a comparação visual entre elas.**"""

import matplotlib.pyplot as plt
from pyspark.sql import functions as F

artist_name = 'Taylor Swift'

artist_data = dataframe.filter(F.col("Artist") == artist_name).select(
    "Spotify Streams", "YouTube Views", "TikTok Views"
).first()

values = [artist_data[i] if artist_data[i] is not None else 0 for i in range(3)]


plt.figure(figsize=(8, 8))
plt.pie(values, labels=['Spotify', 'YouTube', 'TikTok'], autopct='%1.1f%%', startangle=90, colors=['Green', 'Red', 'Blue'])
plt.axis('equal')
plt.title(f'Comparação de Views do {artist_name} nas Plataformas')
plt.show()